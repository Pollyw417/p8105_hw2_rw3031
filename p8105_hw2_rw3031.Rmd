---
title: "homework 2"
author: "Polly Wu (rw3031)"
date: "2024-09-24"
output: github_document
---

```{r setup, echo=FALSE, message = FALSE}
library(tidyverse)
library(readxl)
```

# Problem 1

### import and tidy the NYC transit dataset 

```{r}
subway = 
  read_csv("./NYC_Transit_Subway_Entrance_And_Exit_Data.csv",  
           na = c("NA", ".",""))|>
  janitor::clean_names()|>
  select(line:entry, vending, ada)|>
  mutate(entry = recode(entry, "YES" = TRUE ,"NO" = FALSE))
```
### describe the dataset

The subway dataset contains variables including: `r names(subway)`.

For cleaning up the data, I convert the format of all of the column names into lower case and connected through underscore. I have retain the variables that we are interested in and convert the entry column into a logical variable. 

There are `r ncol(subway)` columns and `r nrow(subway)` rows. 

The data is not tidy since we still have the route column in wide format.Each route is stored in a different column instead of consolidated together.

```{r}
station = distinct(subway,line,station_name, .keep_all = TRUE)
nrow(station)
nrow(filter(station,ada == "TRUE"))
nrow(filter(station,vending == "NO"))/nrow(station)*100
```
There are 465 distinct stations.
84 stations are ADA compliant. 
1.94% of the stations entrance/exit are without vending allow entrance. 

### tidy up the route variable

```{r}
subway =
  subway|>
  mutate(route8 = as.character(route8),
         route9 = as.character(route9),
         route10 = as.character(route10),
         route11 = as.character(route11),)|>
  pivot_longer(
    route1:route11,
    names_to = "route_no",
    names_prefix = "route",
    values_to = "route_name"
  )
```

### A_train stations

```{r}
station = distinct(subway,line,station_name, .keep_all = TRUE)
nrow(filter(station,route_name == "A"))
nrow(filter(station,route_name =="A", ada == "TRUE"))
```
There are 60 distinct stations serve the A train and 17 of them are ADA compliance. 

# Problem 2

### import the trash-wheel dataset 
```{r}
mr_trash = 
  read_excel("./202309 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", skip = 1,  na = c("NA", ".","")) |>
  janitor::clean_names()|>
  mutate(sports_balls=as.integer(sports_balls), 
         type = "mr.",
         year = as.integer(year))
```
```{r}
professor_trash = 
  read_excel("./202309 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", skip = 1,  na = c("NA", ".","")) |>
  janitor::clean_names()|>
  mutate(type = "professor")
```

```{r}
Gwynnda = 
  read_excel("./202309 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", skip = 1,  na = c("NA", ".","")) |>
  janitor::clean_names()|>
  mutate(type = "gwynnda")
```

### merge the three datasets 
```{r}
trash_wheel = 
  bind_rows(mr_trash, professor_trash, Gwynnda)
```

The merged trash_wheel dataset has the follow variables `r names(trash_wheel)`. There are `r nrow(trash_wheel)` observations and `r ncol(trash_wheel)` variables. `

```{r}
sum_professor = 
  professor_trash|>
  summarise(sum(weight_tons, na.rm = FALSE))
sum_gwynnda = 
  Gwynnda|>
  filter(year == 2022, month == "June")|>
  summarise(sum(cigarette_butts, na.rm = FALSE))
```

The total weight of the trash collected by the professor trash wheel is `r sum_professor` tons. The total number of cigarette butts collected by the gwynnda trash wheel in June 2022 is `r sum_gwynnda`.

# Problem 3

### import the data 
```{r}
bakers=
  read_csv("./gbb_datasets/bakers.csv")|>
  janitor::clean_names()|>
  separate(baker_name,into = c("first_name", "last_name"),sep=" ")

bakes=
  read_csv("./gbb_datasets/bakes.csv")|>
  janitor::clean_names()|>
  rename(first_name = baker)

results=
  read_csv("./gbb_datasets/results.csv", skip = 2)|>
  janitor::clean_names()|>
  rename(first_name = baker)
```
I imported the three dataset and just the janitor package to change the format of all variable name to be lowercase and separate with underscore. 

While looking at the three datasets, I discovered that in the results and bakes dataset, we only included the first name of the baker while in the baker dataset, we include the full name of the bakers. Therefore, I separate the name in the baker dataset into two column for first name and last name. I also rename the baker column in the result and bakes dataset as first name in order to match with the bakers dataset. 

For the results dataset, it has a heading which means the first 2 rows of the csv file does not contain any data, so I skip them while importing. 

```{r}
anti_join(results,bakers,by = "first_name")
anti_join(bakers,results,by = "first_name")
anti_join(results,bakes, by = c("series","episode"))
anti_join(bakes, results, by = c("series","episode"))
anti_join(bakes, bakers, by = "first_name")
anti_join(bakers, bakes, by = "first_name")
```
Through anti-join, we found that Baker Joanne from the 2nd series name was mistyped as Jo in the bakers dataset. Therefore I fixed the typo in the bakers dataset. (code below)

In addition, I found that information for the bakes during the 9th and 10th series are missing. 

```{r}
bakers|>
  mutate(first_name = ifelse(first_name == "Jo","Joanne", first_name))
```

### joining the gbb dataset 

```{r}
gbb = 
  left_join(results, bakes, by = c("first_name", "series", "episode"))|>
  left_join(bakers,by = c("first_name", "series"))|>
  relocate(series,episode,first_name,last_name, signature_bake,show_stopper,technical,result,baker_age:hometown)|>
  arrange(series, episode)
```

I merge the three dataset using left join, the bakes and results dataset are matched based on first_name, serires and episode, Then I left join the bakers dataset based on first_name and series. Secondly, I relocate the sequence of the columns to have the series and episode number at first, follows the baker's name, bakers's bakes and result and finally additional information about each baker. I also sort the dataset in the order of the series and episodes. 

### export the gbb dataset 

```{r}
write_csv(gbb,"./gbb_datasets/gbb.csv")
```

### winner and star baker 

```{r}
winner =
  gbb|>
  filter(result %in% c("STAR BAKER","WINNER"), series >= 5)|>
  select(series,episode,first_name,result)|>
  pivot_wider(
    names_from = "result",
    values_from = "first_name"
  )
```

In season 6 to 9 the winner is quite predictable as the winners have all received the star_baker for multiple times. In season 5, Nancy only won one star baker award before becoming the final winner. In season 10, David hasn't been a star baker for anytime before becoming the final winner, which is a surprising result. 

### tidy viewers 

```{r}
viewers=
  read_csv("./gbb_datasets/viewers.csv")|>
  janitor::clean_names()|>
  pivot_longer(
    series_1:series_10,
    names_to = "series",
    names_prefix = "series_", 
    values_to = "viewership"
  )

head(viewers, 10)
```

### obtain the average viewership

```{r}
viewers |>
  filter(series == 1)|>
  summarise(avg_viewership = mean(viewership, na.rm = TRUE))

viewers |>
  filter(series ==5)|>
  summarise(avg_viewership = mean(viewership, na.rm = TRUE))
```
The average viewership is 2.77 in season 1 and 10.0393 in season 5. 
