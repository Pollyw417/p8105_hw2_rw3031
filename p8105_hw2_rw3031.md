homework 2
================
Polly Wu (rw3031)
2024-09-24

# Problem 1

### import and tidy the NYC transit dataset

``` r
subway = 
  read_csv("./NYC_Transit_Subway_Entrance_And_Exit_Data.csv",  
           na = c("NA", ".",""))|>
  janitor::clean_names()|>
  select(line:entry, vending, ada)|>
  mutate(entry = ifelse(entry == "YES", TRUE , FALSE))
```

    ## Rows: 1868 Columns: 32
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (22): Division, Line, Station Name, Route1, Route2, Route3, Route4, Rout...
    ## dbl  (8): Station Latitude, Station Longitude, Route8, Route9, Route10, Rout...
    ## lgl  (2): ADA, Free Crossover
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

### describe the dataset

The subway dataset contains variables including: line, station_name,
station_latitude, station_longitude, route1, route2, route3, route4,
route5, route6, route7, route8, route9, route10, route11, entrance_type,
entry, vending, ada.

For cleaning up the data, I convert the format of all of the column
names into lower case and connected through underscore. I have retain
the variables that we are interested in and convert the entry column
into a logical variable.

There are 19 columns and 1868 rows.

The data is not tidy since we still have the route column in wide
format.Each route is stored in a different column instead of
consolidated together.

``` r
station = distinct(subway,line,station_name, .keep_all = TRUE)
nrow(station)
```

    ## [1] 465

``` r
nrow(filter(station,ada == "TRUE"))
```

    ## [1] 84

``` r
nrow(filter(station,vending == "NO"))/nrow(station)*100
```

    ## [1] 1.935484

There are 465 distinct stations. 84 stations are ADA compliant. 1.94% of
the stations entrance/exit are without vending allow entrance.

### tidy up the route variable

``` r
subway =
  subway|>
  mutate(route8 = as.character(route8),
         route9 = as.character(route9),
         route10 = as.character(route10),
         route11 = as.character(route11),)|>
  pivot_longer(
    route1:route11,
    names_to = "route_no",
    names_prefix = "route",
    values_to = "route_name"
  )
```

### A_train stations

``` r
station = distinct(subway,line,station_name, .keep_all = TRUE)
nrow(filter(station,route_name == "A"))
```

    ## [1] 60

``` r
nrow(filter(station,route_name =="A", ada == "TRUE"))
```

    ## [1] 17

There are 60 distinct stations serve the A train and 17 of them are ADA
compliance.

# Problem 2

### import the trash-wheel dataset

``` r
mr_trash = 
  read_excel("./202409 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", skip = 1,  na = c("NA", ".","")) |>
  janitor::clean_names()|>
  select(dumpster:homes_powered)|>
  mutate(sports_balls=as.integer(sports_balls), 
         type = "mr.",
         year = as.integer(year))
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

``` r
professor_trash = 
  read_excel("./202409 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", skip = 1,  na = c("NA", ".","")) |>
  janitor::clean_names()|>
  mutate(type = "professor")
```

``` r
Gwynnda = 
  read_excel("./202409 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", skip = 1,  na = c("NA", ".","")) |>
  janitor::clean_names()|>
  mutate(type = "gwynnda")
```

### merge the three datasets

``` r
trash_wheel = 
  bind_rows(mr_trash, professor_trash, Gwynnda)
```

The merged trash_wheel dataset has the follow variables dumpster, month,
year, date, weight_tons, volume_cubic_yards, plastic_bottles,
polystyrene, cigarette_butts, glass_bottles, plastic_bags, wrappers,
sports_balls, homes_powered, type. There are 1038 observations and 15
variables. \`

``` r
professor_trash|>
  summarise(sum(weight_tons, na.rm = TRUE))
```

    ## # A tibble: 1 × 1
    ##   `sum(weight_tons, na.rm = TRUE)`
    ##                              <dbl>
    ## 1                              488

``` r
Gwynnda|>
  filter(year == 2022, month == "June")|>
  summarise(sum(cigarette_butts, na.rm = FALSE))
```

    ## # A tibble: 1 × 1
    ##   `sum(cigarette_butts, na.rm = FALSE)`
    ##                                   <dbl>
    ## 1                                 18120

The total weight of the trash collected by the professor trash wheel is
488 tons. The total number of cigarette butts collected by the gwynnda
trash wheel in June 2022 is 18120.

# Problem 3

### import the data

``` r
bakers=
  read_csv("./gbb_datasets/bakers.csv")|>
  janitor::clean_names()|>
  separate(baker_name,into = c("first_name", "last_name"),sep=" ")
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
bakes=
  read_csv("./gbb_datasets/bakes.csv")|>
  janitor::clean_names()|>
  rename(first_name = baker)
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
results=
  read_csv("./gbb_datasets/results.csv", skip = 2)|>
  janitor::clean_names()|>
  rename(first_name = baker)
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

I imported the three dataset and just the janitor package to change the
format of all variable name to be lowercase and separate with
underscore.

While looking at the three datasets, I discovered that in the results
and bakes dataset, we only included the first name of the baker while in
the baker dataset, we include the full name of the bakers. Therefore, I
separate the name in the baker dataset into two column for first name
and last name. I also rename the baker column in the result and bakes
dataset as first name in order to match with the bakers dataset.

For the results dataset, it has a heading which means the first 2 rows
of the csv file does not contain any data, so I skip them while
importing.

``` r
anti_join(results,bakers,by = "first_name")
```

    ## # A tibble: 8 × 5
    ##   series episode first_name technical result    
    ##    <dbl>   <dbl> <chr>          <dbl> <chr>     
    ## 1      2       1 Joanne            11 IN        
    ## 2      2       2 Joanne            10 IN        
    ## 3      2       3 Joanne             1 IN        
    ## 4      2       4 Joanne             8 IN        
    ## 5      2       5 Joanne             6 IN        
    ## 6      2       6 Joanne             1 STAR BAKER
    ## 7      2       7 Joanne             3 IN        
    ## 8      2       8 Joanne             1 WINNER

``` r
anti_join(bakers,results,by = "first_name")
```

    ## # A tibble: 1 × 6
    ##   first_name last_name series baker_age baker_occupation hometown    
    ##   <chr>      <chr>      <dbl>     <dbl> <chr>            <chr>       
    ## 1 Jo         Wheatley       2        41 Housewife        Ongar, Essex

``` r
anti_join(results,bakes, by = c("series","episode"))
```

    ## # A tibble: 250 × 5
    ##    series episode first_name technical result
    ##     <dbl>   <dbl> <chr>          <dbl> <chr> 
    ##  1      9       1 Antony            12 IN    
    ##  2      9       1 Briony             2 IN    
    ##  3      9       1 Dan                4 IN    
    ##  4      9       1 Jon                5 IN    
    ##  5      9       1 Karen              6 IN    
    ##  6      9       1 Kim-Joy           10 IN    
    ##  7      9       1 Luke               8 IN    
    ##  8      9       1 Rahul              7 IN    
    ##  9      9       1 Ruby               1 IN    
    ## 10      9       1 Terry              9 IN    
    ## # ℹ 240 more rows

``` r
anti_join(bakes, results, by = c("series","episode"))
```

    ## # A tibble: 0 × 5
    ## # ℹ 5 variables: series <dbl>, episode <dbl>, first_name <chr>,
    ## #   signature_bake <chr>, show_stopper <chr>

``` r
anti_join(bakes, bakers, by = "first_name")
```

    ## # A tibble: 8 × 5
    ##   series episode first_name signature_bake                          show_stopper
    ##    <dbl>   <dbl> <chr>      <chr>                                   <chr>       
    ## 1      2       1 "\"Jo\""   Chocolate Orange CupcakesOrange and Ca… Chocolate a…
    ## 2      2       2 "\"Jo\""   Caramelised Onion, Gruyere and Thyme Q… Raspberry a…
    ## 3      2       3 "\"Jo\""   Stromboli flavored with Mozzarella, Ha… Unknown     
    ## 4      2       4 "\"Jo\""   Lavender Biscuits                       Blueberry M…
    ## 5      2       5 "\"Jo\""   Salmon and Asparagus Pie                Apple and R…
    ## 6      2       6 "\"Jo\""   Rum and Raisin Baked Cheesecake         Limoncello …
    ## 7      2       7 "\"Jo\""   Raspberry & Strawberry Mousse Cake      Pain Aux Ra…
    ## 8      2       8 "\"Jo\""   Raspberry and Blueberry Mille Feuille   Mini Victor…

``` r
anti_join(bakers, bakes, by = "first_name")
```

    ## # A tibble: 23 × 6
    ##    first_name last_name       series baker_age baker_occupation         hometown
    ##    <chr>      <chr>            <dbl>     <dbl> <chr>                    <chr>   
    ##  1 Alice      Fevronia            10        28 Geography teacher        Essex   
    ##  2 Amelia     LeBruin             10        24 Fashion designer         Halifax 
    ##  3 Antony     Amourdoux            9        30 Banker                   London  
    ##  4 Briony     Williams             9        33 Full-time parent         Bristol 
    ##  5 Dan        Beasley-Harling      9        36 Full-time parent         London  
    ##  6 Dan        Chambers            10        32 Support worker           Rotherh…
    ##  7 Helena     Garcia              10        40 Online project manager   Leeds   
    ##  8 Henry      Bird                10        20 Student                  Durham  
    ##  9 Imelda     McCarron             9        33 Countryside recreation … County …
    ## 10 Jamie      Finn                10        20 Part-time waiter         Surrey  
    ## # ℹ 13 more rows

Through anti-join, we found that Baker Joanne from the 2nd series name
was mistyped as Jo in the bakers dataset. Therefore I fixed the typo in
the bakers dataset. (code below)

In addition, I found that information for the bakes during the 9th and
10th series are missing.

``` r
bakers|>
  mutate(first_name = ifelse(first_name == "Jo","Joanne", first_name))
```

    ## # A tibble: 120 × 6
    ##    first_name last_name   series baker_age baker_occupation             hometown
    ##    <chr>      <chr>        <dbl>     <dbl> <chr>                        <chr>   
    ##  1 Ali        Imdad            4        25 Charity worker               Saltley…
    ##  2 Alice      Fevronia        10        28 Geography teacher            Essex   
    ##  3 Alvin      Magallanes       6        37 Nurse                        Brackne…
    ##  4 Amelia     LeBruin         10        24 Fashion designer             Halifax 
    ##  5 Andrew     Smyth            7        25 Aerospace engineer           Derby /…
    ##  6 Annetha    Mills            1        30 Midwife                      Essex   
    ##  7 Antony     Amourdoux        9        30 Banker                       London  
    ##  8 Beca       Lyne-Pirkis      4        31 Military Wives' Choir Singer Aldersh…
    ##  9 Ben        Frazer           2        31 Graphic Designer             Northam…
    ## 10 Benjamina  Ebuehi           7        23 Teaching assistant           South L…
    ## # ℹ 110 more rows

### joining the gbb dataset

``` r
gbb = 
  left_join(results, bakes, by = c("first_name", "series", "episode"))|>
  left_join(bakers,by = c("first_name", "series"))|>
  relocate(series,episode,first_name,last_name, signature_bake,show_stopper,technical,result,baker_age:hometown)|>
  arrange(series, episode)
```

I merge the three dataset using left join, the bakes and results dataset
are matched based on first_name, serires and episode, Then I left join
the bakers dataset based on first_name and series. Secondly, I relocate
the sequence of the columns to have the series and episode number at
first, follows the baker’s name, bakers’s bakes and result and finally
additional information about each baker. I also sort the dataset in the
order of the series and episodes.

### export the gbb dataset

``` r
write_csv(gbb,"./gbb_datasets/gbb.csv")
```

### winner and star baker

``` r
winner =
  gbb|>
  filter(result %in% c("STAR BAKER","WINNER"), series >= 5)|>
  select(series,episode,first_name,result)|>
  pivot_wider(
    names_from = "result",
    values_from = "first_name"
  )
```

In season 6 to 9 the winner is quite predictable as the winners have all
received the star_baker for multiple times. In season 5, Nancy only won
one star baker award before becoming the final winner. In season 10,
David hasn’t been a star baker for anytime before becoming the final
winner, which is a surprising result.

### tidy viewers

``` r
viewers=
  read_csv("./gbb_datasets/viewers.csv")|>
  janitor::clean_names()|>
  pivot_longer(
    series_1:series_10,
    names_to = "series",
    names_prefix = "series_", 
    values_to = "viewership"
  )
```

    ## Rows: 10 Columns: 11
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (11): Episode, Series 1, Series 2, Series 3, Series 4, Series 5, Series ...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
head(viewers, 10)
```

    ## # A tibble: 10 × 3
    ##    episode series viewership
    ##      <dbl> <chr>       <dbl>
    ##  1       1 1            2.24
    ##  2       1 2            3.1 
    ##  3       1 3            3.85
    ##  4       1 4            6.6 
    ##  5       1 5            8.51
    ##  6       1 6           11.6 
    ##  7       1 7           13.6 
    ##  8       1 8            9.46
    ##  9       1 9            9.55
    ## 10       1 10           9.62

### obtain the average viewership

``` r
viewers |>
  filter(series == 1)|>
  summarise(avg_viewership = mean(viewership, na.rm = TRUE))
```

    ## # A tibble: 1 × 1
    ##   avg_viewership
    ##            <dbl>
    ## 1           2.77

``` r
viewers |>
  filter(series ==5)|>
  summarise(avg_viewership = mean(viewership, na.rm = TRUE))
```

    ## # A tibble: 1 × 1
    ##   avg_viewership
    ##            <dbl>
    ## 1           10.0

The average viewership is 2.77 in season 1 and 10.0393 in season 5.
